<h1>Projects</h1>
<app-projectcard 
    [myimg]="'../../assets/FruitiestPebbles.png'"
    [title]="'County Regionalization Using Federal Data'" 
    [description]="'Regionalization of the United States is omnipresent and informs thinking and decision-making. Are regions as we know them purely cultural, or do they have any basis in statistics? Using economic and demographic data from federal agencies, I set out to answer this question using clustering and predictive modeling to look for regional trends.'"
    [linktarget]="'https://github.com/peckben1/Capstone'"
></app-projectcard>
<app-projectcard
    [myimg]="'../../assets/floodguy.jpg'"
    [title]="'Estimating Flood Depths from Ground Based Imagery'"
    [description]="'In this project for New Light Technologies based on a prompt from FEMA, my colleague Ana Petronijevic and I used a convolutional neural network and image preprocessing to test the possibility of gathering flood depth information from crowdsourced images.'"
    [linktarget]="'https://github.com/peckben1/Flood_Depths'"
></app-projectcard>
<app-projectcard 
    [myimg]="'../../assets/ExMoTapir.png'"
    [title]="'Predicting Reddit Post Origins With Similar Topics'"
    [description]="'The objective of this project is to accurately predict which of two subreddits a post originated in based on the post\'s textual content, even when the two subreddits are on similar topics. In order to achieve this, I built and tested multiple classification models on posts from the r/latterdaysaints and r/exmormon subreddits. Being able to reliably distinguish between two groups interacting with the same topic from different perspectives is of clear consequence to advertisers, campaigners, and others seeking to identify target populations holding or receptive to certain views.'"
    [linktarget]="'https://github.com/peckben1/RedditClassification'"
></app-projectcard>
<app-projectcard 
    [myimg]="'../../assets/IslandMaker.png'"
    [title]="'Island Maker'"
    [description]="'A collaborative effort with Grady Peck, this notebook uses Perlin noise to generate semi-random islands and then simulates flows to appropriately place streams and ponds.'"
    [linktarget]="'https://github.com/peckben1/IslandMaker'"
></app-projectcard>
<app-projectcard 
    [myimg]="'../../assets/ChronAm.png'"
    [title]="'Chronicling America API Bulk Search and Download'"
    [description]="'These Python scripts interact with the Chronicling America API maintained by the Library of Congress to allow targeted bulk search and download, generating metadata files and highlighting terms of interest on downloaded pages. These scripts were written for and used in an active historical research project.'"
    [linktarget]="'https://github.com/peckben1/ChroniclingAmerica'"
></app-projectcard>
<app-projectcard 
    [myimg]="'../../assets/AnchorMen.jpg'"
    [title]="'Link Checker'"
    [description]="'This quick Python script crawls a given website and logs all instances of a target link - extremely useful if every instance of a link needs to be updated or replaced on a large website. It is currently being extended to also check for any broken links, regardless of the target.'"
    [linktarget]="'https://github.com/peckben1/LinkCheck'"
></app-projectcard>
<app-projectcard 
    [myimg]="'../../assets/ZooMap.jpg'"
    [title]="'Flickr API Bulk Scrape for Historical Research'"
    [description]="'For an active historical research project, this notebook was created to retrieve files related to specified job numbers from the Olmsted National Historic Site Flickr account, parse descriptions, and generate a metadata file. Robust to inconsistent, hand-entered data, this notebook has processed around 5,000 images (25 GB worth) in a single run.'"
    [linktarget]="'https://github.com/peckben1/OlmstedScrape'"
></app-projectcard>